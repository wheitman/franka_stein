import cv2
import numpy as np
from matplotlib import pyplot as plt

from autolab_core import RigidTransform
from frankapy import FrankaArm

import math
from sklearn.metrics import pairwise_distances
import fast_tsp


class CameraProcessor:
    def __init__(self):
        self.intensity_threshold = 10

    def segment(self):
        """
        Will's code for segmenting, based on HSV
        :return:
        """
        # Get the color image from the capture
        # ret, color_image = capture.get_color_image()
        fig, axs = plt.subplots(2, 2)
        ax1, ax2, ax3, ax4 = axs.flatten()

        color_image = cv2.imread("example.png")  # TODO: This is where we want the camera input

        # Convert to HSV
        hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)

        refined_image = hsv_image.copy()

        # TODO: Change based on color. Ask Will
        HUE_MIN = 170
        refined_image[refined_image[:, :, 0] < 170] = [0, 0, 0]

        SAT_THRESHOLD = 100
        refined_image[refined_image[:, :, 1] < 80] = [0, 0, 0]

        VAL_MIN = 180
        refined_image[refined_image[:, :, 2] < 180] = [0, 0, 0]

        # Dilate a bit to exagerate result
        kernel = np.ones((5, 5), np.uint8)
        refined_image = cv2.dilate(refined_image, kernel, iterations=1)

        # Show it
        ax1.set_title("Original image")
        ax1.imshow(color_image)
        ax3.set_title("Segmented image")
        ax3.imshow(refined_image)
        ax2.set_title("Saturation")
        ax2.imshow(hsv_image[:, :, 1])
        ax4.set_title("Value")
        ax4.imshow(hsv_image[:, :, 2])
        plt.show()

    def convert_to_binary(self, img, color):
        """
        This returns the mask that we need (adapted from Ishir's code)
        Have to check what works best
        :param img:
        :param color:
        :return:
        """
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        lower = np.array(color) - self.intensity_threshold
        upper = np.array(color) + self.intensity_threshold
        mask = cv2.inRange(img, lower, upper)
        res = cv2.bitwise_and(img, img, mask=mask)
        res = cv2.cvtColor(res, cv2.COLOR_RGB2GRAY)
        res[res > 0] = 255
        return res


class Planner:
    """
    This takes the mask generated by the CameraProcessor and calculates a list of waypoints
    """
    def __init__(self):
        pass



    def get_contours(self, mask):
        """
        Find the contours from the given mask
        :param mask:
        :return:
        """
        contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        return contours

    def get_centers(self, contours):
        """
        Get center from the contours
        :param contours:
        :return:
        """
        centers = []
        for contour in contours:
            M = cv2.moments(contour)
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            centers.append((cX, cY))
        return centers

    def get_index(self, point, centers):
        # For a given center, check its index
        for idx, center in enumerate(centers):
            if (center == point).all():
                return idx

    def account_for_obstacles(self, red_points, obstacle_points, dist_arr):
        all_pairs = [(a, b) for idx, a in enumerate(red_points) for b in red_points[idx + 1:]]

        for idx, pair in enumerate(all_pairs):
            p1, p2 = pair
            for obs in obstacle_points:
                p3 = obs
                d = np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)
                if d < 10:
                    print("Obstacle between ", p1, " and ", p2)
                    bad_indexs.append(idx)

                    p1_index = get_index(p1, red_points)
                    p2_index = get_index(p2, red_points)

                    dist_arr[p1_index][p2_index] = 10000
                    dist_arr[p2_index][p1_index] = 10000

        return dist_arr


class FrankaSteinArm(FrankaArm):
    """
    Controller that will actuate the arm to get the points
    """
    def __init__(self):
        # Start default functionality of the franka arm
        super().__init__()

        # We need to save some special states and info
        # Pose where the robot grasps the eraser
        self.default_gripper_orientation = np.array(
            [[1., 0., 0.],
             [0., -1., 0.],
             [0., 0., -1.]])  # CHANGE IF NEEDED
        self.eraser_position = np.array([0.51414798, 0.36158461, 0.01890064])  # CHANGE IF NEEDED

        self.primer_delta = np.array([0., 0., 0.2])  # Safety so as not to collide with eraser

        self.eraser_grasping_pose = RigidTransform(
            rotation=self.default_gripper_orientation,
            translation=self.eraser_position,
            from_frame="franka_tool", to_frame="world")

        self.eraser_grasping_primed = RigidTransform(
            rotation=self.default_gripper_orientation,
            translation=self.eraser_position + self.primer_delta,
            from_frame="franka_tool", to_frame="world")

        # Useful for surface sliding
        self.surface_level = 0.01

    def catch_eraser(self):
        print("Getting eraser")
        print("Moving to eraser prime")
        self.goto_pose(self.eraser_grasping_primed, use_impedance=False)
        print("Moving to grasp eraser")
        self.goto_pose(self.eraser_grasping_pose, use_impedance=False)
        print("Grasping eraser")
        self.close_gripper()  # Will close until it hits the object. Pretty tight grasp
        print("Lifting eraser")
        self.goto_pose(self.eraser_grasping_primed, use_impedance=False)

    def return_eraser(self):
        print("Returning eraser")
        print("Moving to eraser prime")
        self.goto_pose(self.eraser_grasping_primed, use_impedance=False)
        print("Moving to place eraser")
        self.goto_pose(self.eraser_grasping_pose, use_impedance=False)
        print("Letting go of eraser")
        self.open_gripper()  # Will close until it hits the object. Pretty tight grasp
        print("Lifting hand")
        self.goto_pose(self.eraser_grasping_primed, use_impedance=False)
        print("Sending home")
        self.reset_joints()

    def erase(self, trajectory):
        """
        Erases surface between 2 points
        trajectory: list of points (x, y) indicating a trajectory to clean
        degrades with distance?...
        TODO: Integrate with Ishir's points
        """
        if (len(trajectory) >= 2):
            # Prime for movement in first point
            print("Priming for trajectory")
            p1x, p1y = trajectory[0]
            traj_primer = RigidTransform(
                rotation=self.default_gripper_orientation,
                translation=np.array([p1x, p1y, self.surface_level]) + self.primer_delta,
                from_frame="franka_tool", to_frame="world")
            self.goto_pose(traj_primer, use_impedance=False)

            # Move to first pt
            print("Setting on trajectory")
            traj_start = RigidTransform(
                rotation=self.default_gripper_orientation,
                translation=np.array([p1x, p1y, self.surface_level]),
                from_frame="franka_tool", to_frame="world")
            self.goto_pose(traj_start, use_impedance=False)

            # Go to point
            n_pts = len(trajectory)
            for i in range(n_pts - 1):
                curr_pt = trajectory[i]
                next_pt = trajectory[i + 1]

                # Find orientation between points
                x_hat = np.append(next_pt - curr_pt, 0)
                x_hat = x_hat / np.linalg.norm(x_hat)
                # Arm can't turn more than 90 deg without glitching
                if x_hat @ np.array([1, 0, 0]) < 0:
                    x_hat = -x_hat

                z_hat = np.array([0, 0, -1])

                y_hat = np.cross(z_hat, x_hat)

                rotation_matrix = np.transpose(np.stack([x_hat, y_hat, z_hat], axis=0))

                print("Reaching orientation")
                traj_start = RigidTransform(
                    rotation=rotation_matrix,
                    translation=np.array([curr_pt[0], curr_pt[1], self.surface_level]),
                    from_frame="franka_tool", to_frame="world")
                self.goto_pose(traj_start, use_impedance=False)

                print("Erasing segment")
                traj_end = RigidTransform(
                    rotation=rotation_matrix,
                    translation=np.array([next_pt[0], next_pt[1], self.surface_level]),
                    from_frame="franka_tool", to_frame="world")
                self.goto_pose(traj_end, use_impedance=False)

            # Lift eraser after trajcetory is done
            print("Lifting eraser")
            traj_lift = RigidTransform(
                rotation=self.default_gripper_orientation,
                translation=np.array([trajectory[-1][0], trajectory[-1][1], self.surface_level]) + self.primer_delta,
                from_frame="franka_tool", to_frame="world")
            self.goto_pose(traj_lift, use_impedance=False)
